{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-zaniolo/CEE690-ESAA/blob/main/Lab05_SDP_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d60581d",
      "metadata": {
        "id": "9d60581d"
      },
      "source": [
        "# Lab 3 — Stochastic Dynamic Programming for Lake Operations\n",
        "\n",
        "This notebook shows how to use **stochastic dynamic programming (SDP)** to compute a stationary release policy for a reservoir.\n",
        "\n",
        "- Decision: **daily release** $r_t$  \n",
        "- Uncertainty: **daily inflow** $q_t$\n",
        "\n",
        "We optimize a trade-off between:\n",
        "\n",
        "- **Hydropower production** from releasing water through the turbines\n",
        "- **Meeting agricultural demand**, represented as a penalty for **unmet demand** relative to $D=80\\,\\mathrm{m^3/s}$\n",
        "\n",
        "For SDP we also need a stochastic inflow model, so we approximate inflow uncertainty with a simple empirical distribution built from the historical record.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2efa6126",
      "metadata": {
        "id": "2efa6126"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792b020f",
      "metadata": {
        "id": "792b020f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 150\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "# Data location (raw GitHub URLs work in Colab)\n",
        "DATA_URL = \"https://raw.githubusercontent.com/m-zaniolo/CEE690-ESAA/main/data/\"\n",
        "\n",
        "# Daily inflow time series [m3/s]\n",
        "inflow = np.loadtxt(DATA_URL + \"inflow.txt\", delimiter=\"\\t\")\n",
        "\n",
        "# A few example historical release strategies [m3/s] (used only for comparison plots)\n",
        "release_hist = np.loadtxt(DATA_URL + \"release1.txt\", delimiter=\"\\t\")\n",
        "\n",
        "# Cyclostationary net evaporation series [mm/day] (length 365)\n",
        "# (The repository file name uses 'Gibe1', even though we apply it to this lake model.)\n",
        "evap_mm_day = np.loadtxt(DATA_URL + \"netevap_Gibe1.txt\", delimiter=\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b861cb",
      "metadata": {
        "id": "58b861cb"
      },
      "source": [
        "## 3. Reservoir simulation model\n",
        "\n",
        "We use the same daily mass balance as in Lab 1, implemented in `mass_balance_gibeIII`.\n",
        "\n",
        "$$\n",
        "S_{t+1} = S_t + (q_{t+1} - r_{t+1} - e_t)*\\Delta t\n",
        "$$\n",
        "\n",
        "- $q$: inflow $[\\mathrm{m^3/s}]$  \n",
        "- $r$: release $[\\mathrm{m^3/s}]$  \n",
        "- $e$: evaporation expressed as an equivalent outflow $[\\mathrm{m^3/s}]$  \n",
        "- $\\Delta t$: 1 day in seconds\n",
        "\n",
        "Lab 1 also uses an empirical storage–level relationship to compute the level  from storage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01673ccf",
      "metadata": {
        "id": "01673ccf"
      },
      "outputs": [],
      "source": [
        "# Reservoir parameters (same as Lab 1)\n",
        "S_max = 1.47e10          # [m3] maximum storage\n",
        "sim_step = 60*60*24            # [s] one day\n",
        "stor_to_surface = 0.0142 # surface = stor_to_surface * storage\n",
        "\n",
        "# Storage -> level relationship used in Lab 1 (empirical)\n",
        "# l = 0.0521 * (s**0.3589)\n",
        "\n",
        "def mass_balance_gibeIII(s0, inflow, release, evap_mm_day, S):\n",
        "\n",
        "    # time convention (prepend a dummy value so we can use t+1 indexing)\n",
        "    inflow_ = np.concatenate(([-999], np.asarray(inflow)))\n",
        "    release_ = np.concatenate(([-999], np.asarray(release)))\n",
        "\n",
        "    # initialize storage vector\n",
        "    s = np.zeros(len(inflow_))\n",
        "    s[0] = s0\n",
        "\n",
        "    # define constants\n",
        "    H = len(inflow)  # simulation horizon (days)\n",
        "\n",
        "    for t in range(H):\n",
        "        # evaporation expressed as an equivalent outflow [m3/s]\n",
        "        evaporation_t = evap_mm_day[t % 365] / 1000.0 * s[t] * stor_to_surface / sim_step\n",
        "\n",
        "        # mass balance\n",
        "        s[t+1] = s[t] + (inflow_[t+1] - release_[t+1] - evaporation_t) * sim_step\n",
        "        s[t+1] = min(max(0, s[t+1]), S)  # physical bounds\n",
        "\n",
        "    # storage -> level (same as Lab 1)\n",
        "    l = 0.0521 * (s ** 0.3589)\n",
        "    return s, l\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6631e608",
      "metadata": {
        "id": "6631e608"
      },
      "source": [
        "### Test the simulator\n",
        "\n",
        "We simulate the historical release series as a sanity check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec8c69d",
      "metadata": {
        "id": "4ec8c69d"
      },
      "outputs": [],
      "source": [
        "s0 = 0.7 * S_max\n",
        "\n",
        "# Use the Lab 1 simulator with a historical release series (for comparison)\n",
        "s_hist, l_hist = mass_balance_gibeIII(s0, inflow, release_hist, evap_mm_day, S_max)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(s_hist)\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Storage (m3)\")\n",
        "plt.ylim(0, S_max * 1.05)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(l_hist)\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Level (m)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce9c36f1",
      "metadata": {
        "id": "ce9c36f1"
      },
      "source": [
        "## 4. Objectives\n",
        "\n",
        "We define two **step costs** evaluated each day.\n",
        "\n",
        "### Hydropower\n",
        "We use the same algebraic form you will see again in Lab 2:\n",
        "\n",
        "$$\n",
        "\\texttt{hp}_t = \\ell_t\\, r_t\\, \\texttt{efficiency}\\, g\\, d  10^-3\n",
        "$$\n",
        "\n",
        "Here $\\ell_t$ is the level , $r_t$ is release, $d$ is water density, and $g$ is gravity.\n",
        "`hp1` is a **benefit**, so it enters the scalar step cost with a minus sign.\n",
        "\n",
        "### Agriculture\n",
        "We penalize **unmet demand** relative to $D,\\mathrm{m^3/s}$:\n",
        "\n",
        "$$\n",
        "\\texttt{food}_t = \\max(D-r_t, 0)^2\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### Weighted sum\n",
        "SDP needs a single scalar step cost to minimize. We use:\n",
        "\n",
        "$$\n",
        "g_t = \\lambda\\,\\texttt{food}_t - (1-\\lambda)\\,\\texttt{hp1}_t\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d213a31",
      "metadata": {
        "id": "6d213a31"
      },
      "outputs": [],
      "source": [
        "# Objectives (same as Lab 2)\n",
        "\n",
        "D = 450            # [m3/s] agricultural demand\n",
        "efficiency = 0.90  # turbine efficiency (assumed constant)\n",
        "g = 9.81           # [m/s2]\n",
        "d = 1000.0         # [kg/m3] water density\n",
        "\n",
        "\n",
        "def step_cost_components(l, r):\n",
        "    hp1 = l * r * efficiency * g * d / 10e3\n",
        "    food = (np.maximum(D - r, 0.0)) ** 2\n",
        "    return hp1, food\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f5873b",
      "metadata": {
        "id": "61f5873b"
      },
      "source": [
        "## 5. Stochastic inflow model\n",
        "\n",
        "A basic SDP needs a probability model for inflow. Here we build an **empirical discrete distribution** from the historical inflow record.\n",
        "\n",
        "Option A: bins have the same width, and different probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff115d91",
      "metadata": {
        "id": "ff115d91"
      },
      "outputs": [],
      "source": [
        "def empirical_inflow_distribution_optionA(q_series, n_bins=25):\n",
        "    q = np.asarray(q_series)\n",
        "    q = q[np.isfinite(q)]\n",
        "\n",
        "    edges = np.linspace(q.min(), q.max(), n_bins + 1)\n",
        "    counts, _ = np.histogram(q, bins=edges)\n",
        "    probs = counts / counts.sum()\n",
        "\n",
        "    reps = 0.5 * (edges[:-1] + edges[1:])  # midpoint of each bin\n",
        "    return reps, probs, edges\n",
        "\n",
        "\n",
        "q_vals, q_probs, q_edges = empirical_inflow_distribution_optionA(inflow, n_bins=25)\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(np.arange(len(q_vals)), q_probs)\n",
        "plt.xlabel(\"Inflow bin\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AX-xB5RHhcEB",
      "metadata": {
        "id": "AX-xB5RHhcEB"
      },
      "source": [
        "it is mathematically acceptable for SDP to use equal-width bins. But for hydrologic inflows it is often a poor numerical approximation.\n",
        "If the inflow distribution is strongly right-skewed, then equal-width bins put most samples in the first bin near zero while the long tail gets many bins with tiny probability mass. That has two consequences:\n",
        "\n",
        "\n",
        "*   You get very low resolution where the system spends most of its time. Many distinct low–moderate inflows that matter for day-to-day releases are collapsed into one dominant bin.\n",
        "*   You get noisy information in the tail. High-flow bins have few samples, so their representative value is unstable. Yet those rare events can drive storage and hydropower outcomes.\n",
        "\n",
        "*Option B* Equal-probability (quantile) bins creates bins with equal probability but different widths.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5MDthGmUiNYt",
      "metadata": {
        "id": "5MDthGmUiNYt"
      },
      "outputs": [],
      "source": [
        "def empirical_inflow_distribution(q_series, n_bins=25, rep=\"mean\"):\n",
        "    q = np.asarray(q_series)\n",
        "    q = q[np.isfinite(q)]\n",
        "    q = q[q >= 0]\n",
        "\n",
        "    # Quantile edges\n",
        "    edges = np.quantile(q, np.linspace(0, 1, n_bins + 1))\n",
        "    edges = np.unique(edges)  # handle ties that create repeated edges\n",
        "\n",
        "    # Bin assignment\n",
        "    idx = np.digitize(q, edges[1:-1], right=True)  # 0..(K-1)\n",
        "    K = len(edges) - 1\n",
        "\n",
        "    probs = np.array([(idx == k).mean() for k in range(K)])\n",
        "\n",
        "    reps = np.zeros(K)\n",
        "    for k in range(K):\n",
        "        qk = q[idx == k]\n",
        "        if len(qk) == 0:\n",
        "            reps[k] = 0.5 * (edges[k] + edges[k+1])\n",
        "        else:\n",
        "            reps[k] = qk.mean() if rep == \"mean\" else np.median(qk)\n",
        "\n",
        "    return reps, probs, edges\n",
        "\n",
        "q_vals, q_probs, q_edges = empirical_inflow_distribution(inflow, n_bins=25)\n",
        "\n",
        "# Bin geometry\n",
        "widths = np.diff(q_edges)\n",
        "lefts  = q_edges[:-1]\n",
        "\n",
        "# Probability mass per bin (widths vary; heights are p_k)\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.bar(lefts, q_probs, width=widths, align=\"edge\", edgecolor=\"k\")\n",
        "plt.xlabel(\"Inflow q (m³/s)\")\n",
        "plt.ylabel(\"Probability mass in bin\")\n",
        "plt.title(\"Quantile bins: varying widths (each bin has ~equal probability)\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ed762c5",
      "metadata": {
        "id": "6ed762c5"
      },
      "source": [
        "## 6. SDP formulation\n",
        "\n",
        "**State:** storage $s$ $[\\mathrm{m^3}]$\n",
        "\n",
        "**Action:** release $r$ $[\\mathrm{m^3/s}]$\n",
        "\n",
        "**Transition:** one-day mass balance with a stochastic inflow draw $q$\n",
        "\n",
        "We compute the infinite-horizon discounted value function:\n",
        "\n",
        "$$\n",
        "H(s(t))=\\min_u\\; \\mathbb{E}\\left[g(s,u,q) + \\gamma H(s(t+1))\\right]\n",
        "$$\n",
        "\n",
        "We solve it by **value iteration** on a discretized storage grid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264f275f",
      "metadata": {
        "id": "264f275f"
      },
      "outputs": [],
      "source": [
        "# Discretization grids\n",
        "n_s =\n",
        "s_grid =\n",
        "l_grid = 0.0521 * (s_grid ** 0.3589)\n",
        "\n",
        "\n",
        "# Action grid:\n",
        "r_max = 1200\n",
        "n_r = 36\n",
        "r_grid = np.linspace(0.0, r_max, n_r)\n",
        "\n",
        "gamma = 1   # discount factor (close to 1 -> long horizon)\n",
        "\n",
        "q_vals_arr = np.asarray(q_vals, dtype=float)\n",
        "q_probs_arr = np.asarray(q_probs, dtype=float)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec3a4942",
      "metadata": {
        "id": "ec3a4942"
      },
      "source": [
        "### Value iteration solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d16719",
      "metadata": {
        "id": "85d16719"
      },
      "outputs": [],
      "source": [
        "def solve_sdp_value_iteration(lam, max_iter=1000, tol=1e-3, verbose=True):\n",
        "    \"\"\"Solve the discounted infinite-horizon SDP by value iteration.\n",
        "\n",
        "    We minimize the expected discounted sum of scalar step costs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lam : float\n",
        "        Trade-off parameter in [0, 1].\n",
        "        lam = 1   -> prioritize agriculture (minimize unmet demand)\n",
        "        lam = 0   -> prioritize hydropower (maximize hp1)\n",
        "    \"\"\"\n",
        "    lam = float(lam)\n",
        "\n",
        "    n_s = len(s_grid)\n",
        "    n_r = len(r_grid)\n",
        "\n",
        "    H = np.zeros(n_s, dtype=float)\n",
        "    policy = np.zeros(n_s, dtype=float)\n",
        "\n",
        "    # Allocate these so we can print them\n",
        "    Q = np.zeros((n_s, n_r), dtype=float)\n",
        "    policy_idx = np.zeros(n_s, dtype=int)\n",
        "\n",
        "    for it in range(max_iter):\n",
        "        H_old = H.copy()\n",
        "\n",
        "        for i, s in enumerate(s_grid):\n",
        "\n",
        "            # feasibility check on release (cannot release more than the storage)\n",
        "            r_feas_max = s / sim_step\n",
        "            feasible = (r_grid <= r_feas_max)\n",
        "\n",
        "            # cap release for the transition (so s_next never over-releases)\n",
        "            r_use = np.minimum(r_grid, r_feas_max)\n",
        "\n",
        "            # evaporation as in the lab loop (here: stationary approximation using mean evap)\n",
        "            surface = s * stor_to_surface\n",
        "            evap_outflow = (np.mean(evap_mm_day) / 1000.0) / sim_step * surface  # [m3/s]\n",
        "\n",
        "            # transition for each (q_bin, action)\n",
        "            s_next =\n",
        "            s_next = np.clip(s_next, 0.0, S_max)\n",
        "\n",
        "            # value-to-go at next state\n",
        "            H_next =\n",
        "\n",
        "            # expected value across inflow uncertainty\n",
        "            exp_future =  # (n_r,)\n",
        "\n",
        "            # --- step cost computed for each release decision ---\n",
        "            l_now = l_grid[i]  # or level_from_storage(s) if you prefer\n",
        "            hp1 = l_now * r_grid * efficiency * g * d / 10e3\n",
        "            food = (np.maximum(D - r_grid, 0.0)) ** 2\n",
        "            step_cost_vec = lam * food - (1.0 - lam) * hp1           # (n_r,)\n",
        "\n",
        "            # Bellman update for each action\n",
        "            Q_actions =\n",
        "            Q_actions = Q_actions.copy()\n",
        "            Q_actions[~feasible] = np.inf\n",
        "\n",
        "            Q[i, :] = Q_actions\n",
        "\n",
        "            u_star =\n",
        "            H[i] = Q_actions[u_star]\n",
        "            policy_idx[i] = u_star\n",
        "            policy[i] = r_grid[u_star]\n",
        "\n",
        "        err = float(np.max(np.abs(H - H_old)))\n",
        "        if err < tol:\n",
        "            break\n",
        "\n",
        "    if verbose:\n",
        "        np.set_printoptions(precision=4, suppress=True, linewidth=160)\n",
        "\n",
        "        print(\"Storage grid s_grid (m3):\")\n",
        "        print(\"shape:\", s_grid.shape)\n",
        "        print(s_grid)\n",
        "\n",
        "        print(\"\\nRelease grid r_grid (m3/s):\")\n",
        "        print(\"shape:\", r_grid.shape)\n",
        "        print(r_grid)\n",
        "\n",
        "        print(\"\\nValue function H(s):\")\n",
        "        print(\"shape:\", H.shape)\n",
        "        print(H)\n",
        "\n",
        "        print(\"\\nQ-function Q(s,a): step cost + discounted expected value-to-go\")\n",
        "        print(\"shape:\", Q.shape)\n",
        "        print(Q)\n",
        "\n",
        "        print(\"\\nOptimal release per storage:\")\n",
        "        print(\"shape:\", policy.shape)\n",
        "        print(policy)\n",
        "\n",
        "    return H, policy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d86ffc6",
      "metadata": {
        "id": "0d86ffc6"
      },
      "source": [
        "## 7. Compute policies for several trade-offs\n",
        "\n",
        "We solve the SDP for a set of $\\lambda$ values and plot the resulting policies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vZlstcJfpeCg",
      "metadata": {
        "id": "vZlstcJfpeCg"
      },
      "outputs": [],
      "source": [
        "lam = 0.5\n",
        "solutions = {}\n",
        "\n",
        "H, pol = solve_sdp_value_iteration(lam)\n",
        "solutions = {\"H\": H, \"policy\": pol}\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(s_grid / S_max, solutions[\"policy\"], label=f\"λ={lam}\")\n",
        "plt.plot(D)\n",
        "plt.xlabel(\"Storage / S_max\")\n",
        "plt.ylabel(\"Optimal release (m3/s)\")\n",
        "plt.ylim([0, r_max*1.1])\n",
        "plt.legend()\n",
        "plt.title('Policy')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(s_grid / S_max, H, label=f\"λ={lam}\")\n",
        "plt.plot(D)\n",
        "plt.xlabel(\"Storage / S_max\")\n",
        "plt.ylabel(\"H(s)\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.title('Optimal cost-to-go/penalty')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "810caa49",
      "metadata": {
        "id": "810caa49"
      },
      "outputs": [],
      "source": [
        "lams = [0.0, 0.10, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
        "solutions = {}\n",
        "\n",
        "for k, lam in enumerate(lams):\n",
        "    print(\"\\nSolving for lambda =\", lam)\n",
        "    H, pol = solve_sdp_value_iteration(\n",
        "        lam, verbose=False\n",
        "    )\n",
        "    solutions[lam] = {\"H\": H, \"policy\": pol}\n",
        "\n",
        "plt.figure()\n",
        "for lam in lams:\n",
        "    plt.plot(s_grid / S_max, solutions[lam][\"policy\"], label=f\"λ={lam}\")\n",
        "plt.xlabel(\"Storage / S_max\")\n",
        "plt.ylabel(\"Optimal release (m3/s)\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.title(\"Note: solutions may not be converged. Longer runtime needed\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b641a45",
      "metadata": {
        "id": "7b641a45"
      },
      "source": [
        "## 8. Simulate and evaluate each policy\n",
        "\n",
        "We evaluate each policy by simulating the reservoir over the historical inflow record with `mass_balance_gibeIII`.\n",
        "\n",
        "We report:\n",
        "\n",
        "- Mean hydropower benefit `hp1` (and the equivalent mean power in MW)\n",
        "- Mean unmet-demand penalty `food`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e530a00",
      "metadata": {
        "id": "0e530a00"
      },
      "outputs": [],
      "source": [
        "def simulate_policy(policy_r_on_grid, s0, inflow_series, evap_series):\n",
        "    \"\"\"Simulate a policy over a given inflow record using the Lab 1 simulator.\"\"\"\n",
        "    inflow_series = np.asarray(inflow_series)\n",
        "    T = len(inflow_series)\n",
        "\n",
        "    # Build a release time series from the policy (storage -> release)\n",
        "    r = np.zeros(T)\n",
        "    s_tmp = float(s0)\n",
        "\n",
        "    for t in range(T):\n",
        "        r[t] = float(np.interp(s_tmp, s_grid, policy_r_on_grid))\n",
        "\n",
        "        # One-step update (same mass balance as in mass_balance_gibeIII)\n",
        "        evaporation_t = float(evap_series[t % 365]) / 1000.0 * s_tmp * stor_to_surface / sim_step\n",
        "        s_tmp = s_tmp + (float(inflow_series[t]) - r[t] - evaporation_t) * sim_step\n",
        "        s_tmp = float(np.clip(s_tmp, 0.0, S_max))\n",
        "\n",
        "    # Full simulation with the constructed releases (Lab 1 function)\n",
        "    s, l = mass_balance_gibeIII(s0, inflow_series, r, evap_series, S_max)\n",
        "\n",
        "    # Step costs on decision days t=0..T-1, using level at time t\n",
        "    hp1, food = step_cost_components(l[:-1], r)\n",
        "\n",
        "    return s, l, r, hp1, food\n",
        "\n",
        "def summarize_run(hp1, food):\n",
        "    # hp1 = P / 10e6, so MW = (P / 1e6) = hp1 * 10\n",
        "    mean_power_MW = float(np.mean(hp1) * 10.0)\n",
        "    return {\n",
        "        \"mean_hp1\": float(np.mean(hp1)),\n",
        "        \"mean_power_MW\": mean_power_MW,\n",
        "        \"mean_food_penalty\": float(np.mean(food)),\n",
        "    }\n",
        "\n",
        "results = []\n",
        "s0 = 0.7 * S_max\n",
        "\n",
        "for lam in lams:\n",
        "    s_sim, l_sim, r_sim, hp1_sim, food_sim = simulate_policy(\n",
        "        solutions[lam][\"policy\"], s0, inflow, evap_mm_day\n",
        "    )\n",
        "    summary = summarize_run(hp1_sim, food_sim)\n",
        "    summary[\"lambda\"] = lam\n",
        "    results.append(summary)\n",
        "\n",
        "results = sorted(results, key=lambda d: d[\"lambda\"])\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0603e418",
      "metadata": {
        "id": "0603e418"
      },
      "source": [
        "### Objective-space plot (trade-off curve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9a1415",
      "metadata": {
        "id": "0c9a1415"
      },
      "outputs": [],
      "source": [
        "mean_power = np.array([r[\"mean_power_MW\"] for r in results])\n",
        "mean_food = np.array([r[\"mean_food_penalty\"] for r in results])\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(mean_food, mean_power)\n",
        "\n",
        "for r in results:\n",
        "    plt.text(r[\"mean_food_penalty\"], r[\"mean_power_MW\"], f\"  λ={r['lambda']}\")\n",
        "\n",
        "plt.xlabel(\"Mean unmet-demand penalty  [max(D - r, 0)^2]\")\n",
        "plt.ylabel(\"Mean power (MW)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a9c7d02",
      "metadata": {
        "id": "7a9c7d02"
      },
      "source": [
        "### Time series example\n",
        "\n",
        "Below we plot storage, release, and power for one policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3391b9c1",
      "metadata": {
        "id": "3391b9c1"
      },
      "outputs": [],
      "source": [
        "lam_show = 0.1\n",
        "s_sim, l_sim, r_sim, hp1_sim, food_sim = simulate_policy(\n",
        "    solutions[lam_show][\"policy\"], s0, inflow, evap_mm_day\n",
        ")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(s_sim / S_max)\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Storage / S_max\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(r_sim, label=\"Optimized release\")\n",
        "plt.axhline(D, linestyle=\"--\", label=\"Demand D=80\")\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Release (m3/s)\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hp1_sim * 10.0)\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Power (MW)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(food_sim)\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Unmet-demand penalty  [max(D - r, 0)^2]\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d6b8b08",
      "metadata": {
        "id": "1d6b8b08"
      },
      "source": [
        "## 9. Discussion and extensions\n",
        "\n",
        "1. **Scaling and weights.** Hydropower and demand deviation have different units. We normalized both terms to make $\\lambda$ more interpretable.\n",
        "\n",
        "2. **Seasonality.** We used a *mean* evaporation term in the SDP to keep the problem stationary. A more realistic SDP can include a seasonal index in the state, for example $x_t=(s_t,\\mathrm{day\\_of\\_year})$.\n",
        "\n",
        "3. **Operational constraints.** You can add turbine capacity, minimum environmental flow, ramping limits, or piecewise costs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c93e0552",
      "metadata": {
        "id": "c93e0552"
      },
      "source": [
        "## 10. Seasonal SDP extension\n",
        "\n",
        "In the stationary SDP above, we approximate inflow as an i.i.d. draw from a single empirical distribution.\n",
        "\n",
        "Here we show what changes if inflow is **seasonal**. The state becomes:\n",
        "\n",
        "- storage $s$\n",
        "- day of year $t \\in \\{1,\\dots,365\\}$\n",
        "\n",
        "We keep the same step cost. We make the inflow distribution time-varying by estimating\n",
        "$\\Pr(q \\mid t)$ from the historical inflow record using a moving window around each day of the year.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b577526",
      "metadata": {
        "id": "5b577526"
      },
      "source": [
        "## Seasonal inflow probabilities\n",
        "\n",
        "Here we estimate a *day-of-year* inflow distribution, \\(P(q \\mid t)\\), using the same inflow support \\((q\\_edges, q\\_vals)\\) used in the stationary SDP.  \n",
        "For each day \\(t\\), we pool observations from a \\(\\pm 15\\)-day window to reduce sampling noise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dc5508a",
      "metadata": {
        "id": "0dc5508a"
      },
      "outputs": [],
      "source": [
        "# --- Estimate daily inflow probabilities P(q | day) on the existing inflow support ---\n",
        "\n",
        "lam_seasonal = 0.25  # pick one trade-off value for the seasonal demo\n",
        "T = 365\n",
        "\n",
        "# Day-of-year index for each inflow observation.\n",
        "# The dataset is daily, so we map index -> day of year by modulo 365.\n",
        "doy_obs = (np.arange(len(inflow)) % 365) + 1  # 1..365\n",
        "\n",
        "window = 15  # +/- days around each target day\n",
        "K = len(q_vals)\n",
        "\n",
        "q_probs_by_day = np.zeros((T, K), dtype=float)\n",
        "\n",
        "for t in range(1, T + 1):\n",
        "    dist = np.abs(doy_obs - t)\n",
        "    dist = np.minimum(dist, 365 - dist)  # circular distance on {1..365}\n",
        "    mask = dist <= window\n",
        "\n",
        "    counts, _ = np.histogram(np.asarray(inflow)[mask], bins=q_edges)\n",
        "\n",
        "    if counts.sum() == 0:\n",
        "        q_probs_by_day[t - 1, :] = q_probs_arr  # fallback to stationary\n",
        "    else:\n",
        "        q_probs_by_day[t - 1, :] = counts / counts.sum()\n",
        "\n",
        "print(\"q_probs_by_day shape:\", q_probs_by_day.shape)\n",
        "\n",
        "# Plot: a heatmap of daily probabilities (day on x, inflow-bin index on y)\n",
        "plt.figure(figsize=(9, 3.8))\n",
        "plt.imshow(q_probs_by_day.T, aspect=\"auto\", origin=\"lower\",\n",
        "           extent=[1, 365, 0, K-1])\n",
        "plt.xlabel(\"Day of year\")\n",
        "plt.ylabel(\"Inflow bin index\")\n",
        "plt.title(\"Estimated inflow probabilities by day (15-day window)\")\n",
        "plt.colorbar(label=\"Probability\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c164a855",
      "metadata": {
        "id": "c164a855"
      },
      "source": [
        "## Seasonal SDP with value iteration\n",
        "\n",
        "We now solve a periodic SDP where the state is \\((t, s)\\).  \n",
        "The transition depends on the day through \\(P(q \\mid t)\\). We keep the same storage and release grids used above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "599065f8",
      "metadata": {
        "id": "599065f8"
      },
      "outputs": [],
      "source": [
        "def solve_seasonal_sdp_value_iteration(lam, q_probs_by_day, max_iter=300, tol=1e-4, verbose=True):\n",
        "    \"\"\"Seasonal SDP by value iteration.\n",
        "\n",
        "    State: (day of year t, storage s)\n",
        "    Action: release r\n",
        "\n",
        "    We minimize: step_cost + gamma * E[ H(t+1, s_next) ]\n",
        "    using a periodic year (t_next = (t+1) mod 365).\n",
        "    \"\"\"\n",
        "    lam = float(lam)\n",
        "\n",
        "    T = q_probs_by_day.shape[0]\n",
        "    K = q_probs_by_day.shape[1]\n",
        "    n_s = len(s_grid)\n",
        "    n_r = len(r_grid)\n",
        "\n",
        "    H = np.zeros((T, n_s), dtype=float)\n",
        "    policy = np.zeros((T, n_s), dtype=float)\n",
        "    policy_idx = np.zeros((T, n_s), dtype=int)\n",
        "\n",
        "    for it in range(max_iter):\n",
        "        H_old = H.copy()\n",
        "\n",
        "        for t in range(T):\n",
        "            t_next = (t + 1) % T\n",
        "            p = q_probs_by_day[t, :]  # (K,)\n",
        "\n",
        "            for i, s in enumerate(s_grid):\n",
        "                # Feasibility: cannot release more than current storage over one step\n",
        "                r_feas_max = s / sim_step\n",
        "                feasible = (r_grid <= r_feas_max)\n",
        "\n",
        "                # Transition uses capped release (so s_next never “over-releases”)\n",
        "                r_use = np.minimum(r_grid, r_feas_max)\n",
        "\n",
        "                surface = s * stor_to_surface\n",
        "                evap_outflow = (evap_mm_day[t % 365] / 1000.0) / sim_step * surface  # [m3/s]\n",
        "\n",
        "                s_next = s + (q_vals_arr[:, None] - r_use[None, :] - evap_outflow) * sim_step\n",
        "                s_next = np.clip(s_next, 0.0, S_max)  # (K, n_r)\n",
        "\n",
        "                # Interpolate value at next storages for next day\n",
        "                H_next = np.interp(s_next, s_grid, H_old[t_next])  # (K, n_r)\n",
        "\n",
        "                exp_future = (p[:, None] * H_next).sum(axis=0)  # (n_r,)\n",
        "\n",
        "                # --- step cost computed inside the loop (state-dependent) ---\n",
        "                l_now = l_grid[i]  # or level_from_storage(s) if you prefer\n",
        "                hp1 = l_now * r_grid * efficiency * g * d / 10e3\n",
        "                food = (np.maximum(D - r_grid, 0.0)) ** 2\n",
        "                step_cost_vec = lam * food - (1.0 - lam) * hp1  # (n_r,)\n",
        "\n",
        "                Q_actions = step_cost_vec + gamma * exp_future\n",
        "\n",
        "                # Enforce feasibility in argmin\n",
        "                Q_actions = Q_actions.copy()\n",
        "                Q_actions[~feasible] = np.inf\n",
        "\n",
        "                j_star = int(np.argmin(Q_actions))\n",
        "                H[t, i] = Q_actions[j_star]\n",
        "                policy_idx[t, i] = j_star\n",
        "                policy[t, i] = r_grid[j_star]\n",
        "\n",
        "        err = float(np.max(np.abs(H - H_old)))\n",
        "        if err < tol:\n",
        "            if verbose:\n",
        "                print(f\"Seasonal SDP converged in {it+1} iterations (max ΔV = {err:.2e}).\")\n",
        "            break\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"Seasonal SDP reached max_iter={max_iter} (max ΔV = {err:.2e}).\")\n",
        "\n",
        "    # Compute and store the full Q matrix for Jan 1 (t=0) for visualization\n",
        "    t0 = 0\n",
        "    t1 = 1  # Jan 2\n",
        "    p0 = q_probs_by_day[t0, :]\n",
        "\n",
        "    Q_jan1_sa = np.zeros((n_s, n_r), dtype=float)  # rows: storage, cols: action\n",
        "\n",
        "    for i, s in enumerate(s_grid):\n",
        "        r_feas_max = s / sim_step\n",
        "        feasible = (r_grid <= r_feas_max)\n",
        "        r_use = np.minimum(r_grid, r_feas_max)\n",
        "\n",
        "        surface = s * stor_to_surface\n",
        "        evap_outflow = (evap_mm_day[t0 % 365] / 1000.0) / sim_step * surface  # Jan 1 evap\n",
        "\n",
        "        s_next = s + (q_vals_arr[:, None] - r_use[None, :] - evap_outflow) * sim_step\n",
        "        s_next = np.clip(s_next, 0.0, S_max)  # (K, n_r)\n",
        "\n",
        "        H_next = np.interp(s_next, s_grid, H[t1])        # (K, n_r)\n",
        "        exp_future = (p0[:, None] * H_next).sum(axis=0)  # (n_r,)\n",
        "\n",
        "        l_now = l_grid[i]\n",
        "        hp1 = l_now * r_grid * efficiency * g * d / 10e3\n",
        "        food = (np.maximum(D - r_grid, 0.0)) ** 2\n",
        "        step_cost_vec = lam * food - (1.0 - lam) * hp1\n",
        "\n",
        "        Qa = step_cost_vec + gamma * exp_future\n",
        "        Qa = Qa.copy()\n",
        "        Qa[~feasible] = np.inf\n",
        "        Q_jan1_sa[i, :] = Qa\n",
        "\n",
        "    Q_jan1_as = Q_jan1_sa.T  # for printing as Q(a, s)\n",
        "\n",
        "    if verbose:\n",
        "        np.set_printoptions(precision=4, suppress=True, linewidth=160)\n",
        "\n",
        "        print(\"\\n==============================\")\n",
        "        print(\"SEASONAL SDP: ARRAY SIZES\")\n",
        "        print(\"==============================\\n\")\n",
        "\n",
        "        print(f\"Days (T): {T}\")\n",
        "        print(f\"Storage states (n_s): {n_s}\")\n",
        "        print(f\"Release actions (n_r): {n_r}\")\n",
        "        print(f\"Inflow bins (K): {K}\")\n",
        "\n",
        "        print(\"\\nH(t, s) shape:\", H.shape)\n",
        "        print(\"Q(Jan 1 as Q(a, s)) shape:\", Q_jan1_as.shape)\n",
        "        print(\"Policy(t, s) shape:\", policy.shape)\n",
        "\n",
        "    return H, policy, policy_idx, Q_jan1_as\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_4qgQH-ESf1x",
      "metadata": {
        "id": "_4qgQH-ESf1x"
      },
      "outputs": [],
      "source": [
        "H, policy, policy_idx, Q_jan1_as = solve_seasonal_sdp_value_iteration(lam, q_probs_by_day)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12aea40f",
      "metadata": {
        "id": "12aea40f"
      },
      "source": [
        "## Plot the seasonal optimal policy\n",
        "\n",
        "We plot one optimal release curve per day. The color goes from light (Jan 1) to dark (Dec 31).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18ddf4ff",
      "metadata": {
        "id": "18ddf4ff"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(7, 5))\n",
        "cmap = plt.cm.viridis\n",
        "\n",
        "for t in range(T):\n",
        "    shade = 0.15 + 0.85 * (t / (T - 1))\n",
        "    ax.plot(s_grid / S_max, policy[t, :], color=cmap(shade), linewidth=0.7)\n",
        "\n",
        "ax.set_xlabel(\"Storage / S_max\")\n",
        "ax.set_ylabel(\"Optimal release (m3/s)\")\n",
        "ax.set_title(f\"Seasonal optimal release policy (one line per day), λ={lam_seasonal}\")\n",
        "\n",
        "import matplotlib as mpl\n",
        "sm = mpl.cm.ScalarMappable(cmap=cmap, norm=mpl.colors.Normalize(vmin=1, vmax=365))\n",
        "sm.set_array([])\n",
        "cbar = fig.colorbar(sm, ax=ax, pad=0.02)\n",
        "cbar.set_label(\"Day of year (1=Jan 1, 365=Dec 31)\")\n",
        "\n",
        "ax.grid(True, alpha=0.2)\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}